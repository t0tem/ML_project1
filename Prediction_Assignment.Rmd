---
title: "Prediction Assignment Writeup"
author: "Vadim K."
date: '2017-03-05'
output:
  html_document:
    keep_md: yes
  pdf_document: default
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Synopsis
The goal of this project is to study the data from devices tracking physical activities of several enthusiasts and predict the manner in which they did the exercise.  
The data comes from http://groupware.les.inf.puc-rio.br/har in 2 files representing training and testing data sets.  
We will import and transform the data, choose variables, study several models and finish with building a prediction algorithm and use it to predict output on test data set. 

# Data Processing 

Loading the needed packages
```{r}
library(caret)
library(rpart)
library(e1071)
library(randomForest)
```

Downloading files and storing them in `data` folder (if not yet there)
```{r}
url1 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url2 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("data/pml-training.csv")) {
      download.file(url1, "data/pml-training.csv")
}
if(!file.exists("data/pml-testing.csv")) {
      download.file(url2, "data/pml-testing.csv")
}
```

Reading data
```{r}
training <- read.csv("data/pml-training.csv")
testing <- read.csv("data/pml-testing.csv")
```

Let's take a look at dimensions of our data set
```{r}
dim(training)
```

And the structure of the data (output omitted as it's too long)
```{r results='hide'}
str(training)
```
we see that many variables contain some missing values.  
So next move is to remove from training set all variables with NA's
```{r}
training <- training[, colSums(is.na(training)) == 0]
```

Now let's identify and eliminate variables with variance close to zero, we'll use function `nearZeroVar` from caret package for this
```{r}
nZeroVar <- nearZeroVar(training)
training <- training[, -nZeroVar]
```

Let's take a look at the names of variables left in our data set
```{r}
names(training)
```

It looks like first 5 of them are not that useful (user name, time stamp, etc..) so we get rid of them
```{r}
training <- training[, -c(1:5)]
```

# Prediction algorithm choosing

For further estimation of out-of-sample error we will divide the initial training set on two: sub-training and validation.
```{r}
seed <- 232323
set.seed(seed)
inTrain <- createDataPartition(training$classe, p = 3/4)[[1]]
sub.training <- training[inTrain, ]
validation <- training[-inTrain, ]
```

## Decision tree
First let's fit a model based on Decision tree method and build the prediction on validation set.
```{r}
fit_dt <- rpart(classe ~., data = sub.training)
pred_dt <- predict(fit_dt, newdata = validation, type = "class")

confusionMatrix(pred_dt, validation$classe)
```

Accuracy of our prediction is 78.83% and the estimation of out-of sample error is 21%
```{r}
unname(1 - confusionMatrix(pred_dt, validation$classe)$overall[1])
```
Not very impresssive... Let's try something else.

## Support Vector Machines

```{r}
tr_control <- trainControl(method="cv", number = 3)
set.seed(seed)

fit_svm <- svm(classe ~., data = sub.training, trControl=tr_control)
pred_svm <- predict(fit_svm, newdata = validation)
confusionMatrix(pred_svm, validation$classe)
```


## Random Forest

```{r}
fit_rf <- randomForest(classe ~., data = sub.training, trControl=tr_control)
pred_rf <- predict(fit_rf, newdata = validation)
confusionMatrix(pred_rf, validation$classe)
```



